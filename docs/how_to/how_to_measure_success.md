---
layout: page
title: How to measure success
parent: How to
nav_order: 6
has_toc: false
---

# How to Measure Success

With in-person events, the number of interactions with researchers can be a key
metric to understand the reach of the event, along with the qualitative metrics
of how engaged those individuals were (did they ask questions and did they feel
like they received the help they were looking for?). Metrics for a virtual event
are certainly quite different, though. With an event held primarily on Twitter,
there are a number of different metrics that can be tracked using simple and
fairly cheap applications. These metrics include:

● Impressions: Number of times twitter users have seen posts containing the
tracked hashtag (one user can make multiple impressions and this may only mean
that it showed up in their Twitter feed)

● Posts: Number of posts that used the hashtag

● Reach: Number of unique users who have seen a post containing the tracked
hashtag (posts with this hashtag showed up in the feed of this many people)

● Engagement: Number of intentional interactions (retweets and likes) with a
post containing the hashtag

● Users: Number of users who posted with the hashtag

While the metrics above can demonstrate that the event had a broad reach, none
of them capture how engaged individuals are with the resources they see - this
is something that could be at least qualitatively assessed at an in-person
event. In addition, the organizers of past Data Help Desks do not weigh heavily
the number of questions asked at the events because we believe that it will take
time for researchers to understand what questions the Data Help Desk can help
them address and it may take them time to realize what questions they should
have. The value of raising awareness of FAIR concepts and techniques cannot be
overlooked and can be of great benefit to funders, publishers, journal editors,
data facility professionals, and others looking for a mechanism to share leading
practices.

One final note on metrics: you will want to track metrics for the volunteer
experts to try to assess their overall satisfaction with the activity and to
find ways to maximize the return on their investment of time. The number of
volunteers can be telling, as can a post-event survey shared with them. Tracking
engagement related to their contributed resources can also demonstrate value to
the volunteers.

## Measure

The success of a data help desk can be measured through a variety of
quantitative and qualitative methods, as indicated in the sources. Here are some
key ways to determine if a data help desk has been successful:

-   **Number of interactions:** The **quantity of people interacting with the
    help desk** is a direct measure of its reach and visibility. This can be
    tracked for both in-person and virtual events.
-   **Question and answer quality:** Assessing the **quality of the questions
    asked and the answers provided** is crucial. This might involve anecdotal
    feedback from users and volunteers or a more formal review process.
-   **Recording questions and answers:** **Keeping a record of the questions
    asked and the answers given** allows organizers to identify recurring
    themes, knowledge gaps in the community, and areas where more resources are
    needed. This record can also inform future training and content development.
-   **Surveys and questionnaires:** Utilizing **surveys and questionnaires** at
    different stages (before, during, and after the help desk) can provide
    valuable insights.
    -   **User surveys** can gauge satisfaction with the help received, identify
        unmet needs, and gather feedback on the effectiveness of the service.
        High levels of satisfaction reported by users indicate success.
    -   **Volunteer surveys** can assess their experience, identify areas for
        improvement in the organization and support provided to them, and
        determine their willingness to participate in future events.
-   **Qualitative engagement (in-person):** For physical help desks, observing
    the **level of engagement** of individuals can be informative. Did they ask
    follow-up questions? Did they seem satisfied with the information they
    received?
-   **Metrics for virtual events:** For virtual data help desks, especially
    those utilizing platforms like Twitter, several metrics can be tracked:
    -   **Impressions:** The number of times posts containing the tracked
        hashtag were seen by users.
    -   **Posts:** The total number of posts using the hashtag.
    -   **Reach:** The number of unique users who saw posts with the hashtag.
    -   **Engagement:** The number of intentional interactions like retweets and
        likes.
    -   **Users:** The number of individual users who posted with the hashtag.
        These metrics can demonstrate the broad reach of the virtual event.
-   **Volunteer satisfaction:** Ensuring that **volunteers feel their time was
    well spent** and are willing to participate in the future is a key indicator
    of a successful and sustainable data help desk. Tracking engagement with
    their contributed resources can also demonstrate value.
-   **Understanding community needs:** The **types of questions asked** can
    highlight the community's areas of need and inform future efforts in data
    management training and resource development. Analyzing the questions can
    reveal recurring challenges, such as acquiring data, data cleaning,
    archiving, and understanding FAIR principles.
-   **Long-term impact:** While harder to measure immediately, the long-term
    success could be reflected in **improved data management practices** within
    the community and an increased understanding and adoption of FAIR
    principles.

It's important to note that organizers do not always weigh heavily the number of
questions asked, especially in the initial stages, as it may take time for
researchers to understand the help desk's purpose and the types of questions
they can ask. Raising awareness of key concepts like FAIR data can also be
considered a success in itself.
